{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBjKiLi_oxxC"
   },
   "source": [
    "## **Long-form Transcription with Thonburian Whisper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibbBX6FxoeON"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install attacut\n",
    "!pip install ssg\n",
    "!pip install datasets\n",
    "!pip install pyarrow==15.0.2\n",
    "!pip install pydub\n",
    "!pip install ipywebrtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAigVlqAo_no"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/biodatlab/thonburian-whisper/\n",
    "!cp ./thonburian-whisper/longform_transcription/sentence_segment.py .\n",
    "!cp ./thonburian-whisper/longform_transcription/utils.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etCjbQrCoaNS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Audio, Dataset\n",
    "from transformers import pipeline\n",
    "from sentence_segment import SyllableSegmentation\n",
    "from utils import convert_mp4_to_wav, perform_vad, generate_srt, burn_srt_to_video\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9J42MOnBtgFf"
   },
   "outputs": [],
   "source": [
    "class LongformTranscriber:\n",
    "    \"\"\"\n",
    "    A class for transcribing long-form audio files using a pre-trained ASR model.\n",
    "\n",
    "    sr (int): Sampling rate for audio processing.\n",
    "    model_path (str): Path to the pre-trained ASR model.\n",
    "    chunk_length_s (int): Length of audio chunks for processing in seconds.\n",
    "    batch_size (int): Batch size for ASR inference.\n",
    "    language (str): Language code for transcription (e.g., \"th\" for Thai).\n",
    "    segment_duration (float): Duration for syllable segmentation in seconds.\n",
    "    pipe (Pipeline): Hugging Face Transformers pipeline for ASR.\n",
    "    ss (SyllableSegmentation): Instance of SyllableSegmentation for post-processing.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        sr: int = 16000,\n",
    "        model_path: str = \"biodatlab/whisper-th-medium-combined\",\n",
    "        chunk_length_s: int = 30,\n",
    "        batch_size: int = 4,\n",
    "        language: str = \"th\",\n",
    "        segment_duration: float = 4.0\n",
    "    ):\n",
    "        self.sr = sr\n",
    "        self.model_path = model_path\n",
    "        self.chunk_length_s = chunk_length_s\n",
    "        self.batch_size = batch_size\n",
    "        self.language = language\n",
    "        self.segment_duration = segment_duration\n",
    "\n",
    "        # Initialize ASR pipeline\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.pipe = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=self.model_path,\n",
    "            chunk_length_s=self.chunk_length_s,\n",
    "            device=device,\n",
    "            torch_dtype=torch.float16,\n",
    "        )\n",
    "\n",
    "        self.ss = SyllableSegmentation()\n",
    "\n",
    "    def convert_audio_to_wav(self, audio_file, target_sr):\n",
    "        \"\"\"\n",
    "        Convert an audio file to WAV format with a specified sampling rate.\n",
    "        \"\"\"\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        audio = audio.set_frame_rate(target_sr).set_channels(1)\n",
    "        output_wav_file = audio_file.rsplit('.', 1)[0] + \"_converted.wav\"\n",
    "        audio.export(output_wav_file, format=\"wav\")\n",
    "        return output_wav_file\n",
    "\n",
    "    def transcribe(self, audio_path: str):\n",
    "        \"\"\"\n",
    "        Transcribe a long-form audio file.\n",
    "\n",
    "        Inputs:\n",
    "            audio_path (str): Path to the input audio file.\n",
    "        Return:\n",
    "            list: A list of segments, each containing transcription with start, stop time.\n",
    "        \"\"\"\n",
    "        if audio_path.endswith('.mp4'):\n",
    "            wav_file = self.convert_mp4_to_wav(audio_path)\n",
    "        elif audio_path.endswith('.wav'):\n",
    "            # Check sampling rate and convert if necessary\n",
    "            audio = AudioSegment.from_wav(audio_path)\n",
    "            if audio.frame_rate != self.sr:\n",
    "                wav_file = self.convert_audio_to_wav(audio_path, self.sr)\n",
    "            else:\n",
    "                wav_file = audio_path\n",
    "        else:  # Assuming other audio formats such as .mp3, etc.\n",
    "            wav_file = self.convert_audio_to_wav(audio_path, self.sr)\n",
    "\n",
    "        _, chunklist = perform_vad(wav_file, 'temp_directory_for_chunks')\n",
    "\n",
    "        # for faster inference, create dataset\n",
    "        audio_dataset = Dataset.from_dict({\"audio\": [c[\"fname\"] for c in chunklist]}).cast_column(\"audio\", Audio())\n",
    "\n",
    "        prediction_gen = self.pipe(\n",
    "            audio_dataset[\"audio\"],\n",
    "            generate_kwargs={\"task\": \"transcribe\", \"language\": self.language},\n",
    "            return_timestamps=False,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "        predictions = [out for out in prediction_gen]\n",
    "        vad_transcriptions = {\n",
    "            \"start\": [(chunk[\"start\"] / self.sr) for chunk in chunklist],\n",
    "            \"end\": [(chunk[\"end\"] / self.sr) for chunk in chunklist],\n",
    "            \"prediction\": [pred[\"text\"] for pred in predictions]\n",
    "        }\n",
    "        uncorrected_segments = self.ss(vad_transcriptions=vad_transcriptions, segment_duration=self.segment_duration)\n",
    "        return uncorrected_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O30YA7GWq86Q"
   },
   "outputs": [],
   "source": [
    "# This is to test recording with IPython widget.\n",
    "# Discard this cell if you want to use `audio.mp3`.\n",
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "camera = CameraStream(constraints={'audio': True, 'video': False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE58imYer4gH"
   },
   "outputs": [],
   "source": [
    "# Save recorded audio to audio.mp3\n",
    "# Discard this line if you want to transcribe an audio file directly\n",
    "recorder.save(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88_-gIUfuR6R"
   },
   "source": [
    "Create `LongformTranscriber` and transcribe `audio.mp3` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjw92CgPtmoF",
    "outputId": "593fcadb-2960-44f7-d0bf-5cfd13d27c84"
   },
   "outputs": [],
   "source": [
    "transcriber = LongformTranscriber(\n",
    "    sr=16000,\n",
    "    model_path=\"biodatlab/whisper-th-medium-combined\",\n",
    "    chunk_length_s=30,\n",
    "    batch_size=4,\n",
    "    language=\"th\",\n",
    "    segment_duration=4.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "AzOpTeuwr-j0",
    "outputId": "80c1a459-0cd6-4a70-b83c-ad2e13efefa3"
   },
   "outputs": [],
   "source": [
    "transcriptions = transcriber.transcribe(\"audio.mp3\")\n",
    "pd.DataFrame(transcriptions)  # transcription in Dataframe format (text, start, end)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
